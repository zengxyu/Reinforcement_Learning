Time step i:  1075000 ; Converging or not:  True ;delta:  0.009908842148497854
The average length of episodes: 19.61508558139535
The average total reward of episode: 341.31617023255814
The number of correct policy: 19 /24
State values:
  25.339   34.584   39.993    0.000    0.000    0.000  974.796
  24.039   32.406   50.941   32.730    0.000  754.390    0.000
  19.168    0.000    0.000  128.547    0.000  365.030  449.750
  20.960   15.087    0.000  222.686  213.933    0.000  391.177
  10.206    9.334    0.000  226.263  267.977  312.396  341.009
State values ==================================END

State Counts:
179540.000 267401.000 313872.000 7345.000 99070.000 409105.000 127909.000
260695.000 215061.000 256763.000 110296.000 36500.000 450276.000 151900.000
124641.000 2104.000 103863.000 278069.000 11990.000 132079.000 436702.000
155457.000 18509.000 69753.000 276339.000 163248.000 13251.000 520556.000
118112.000 6421.000 5229.000 133199.000 420672.000 352259.000 452320.000
State Counts ==================================END

Output optimal policy with arrows:
   ↓        →        ↓        ●        ●        ●        ↖
   ↗        ↗        ↘        ↓        ●        ↑        ●
   ↖        ●        ●        ↓        ●        ↑        ↖
   ↖        ←        ●        ↘        ↙        ●        ↗
   ↑        ↖        ●        →        ↘        →        ↗
Optimal policy ==================================END