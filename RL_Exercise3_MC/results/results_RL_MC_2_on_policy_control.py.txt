Time step i:  975000 ; Converging or not:  True ;delta:  0.009806428805953171
The average length of episodes: 11.122495384615384
The average total reward of episode: 291.73834256410254
The number of correct policy: 13 /24
State values: 
  24.185   33.073   41.031    0.000    0.000    0.000  971.522 
  20.725   19.350   38.285   64.221    0.000  750.953    0.000 
  16.349    0.000    0.000  152.424    0.000  434.284  352.601 
   9.143    3.091    0.000  217.964  256.640    0.000  349.580 
   3.656    4.001    0.000  222.445  244.979  285.062  287.293 
State values ==================================END

State Counts: 
260158.000 312428.000 236847.000 7477.000 4045.000 325135.000 104237.000 
264808.000 231137.000 173458.000 174809.000 8880.000 360713.000 247612.000 
74525.000 52550.000 99778.000 283555.000 11252.000 349894.000 188286.000 
163083.000 26569.000 65009.000 67220.000 288273.000 72054.000 188048.000 
122038.000 10349.000 2515.000 25114.000 68937.000 141009.000 128744.000 
State Counts ==================================END

Output optimal policy with arrows:
   →        →        ↓        ●        ●        ●        ↖     
   ↗        ↖        ↓        ↙        ●        ↗        ●     
   ↑        ●        ●        ↓        ●        ↗        ↑     
   ↖        ←        ●        ↘        →        ●        ↑     
   ↑        ↖        ●        →        ↘        →        →     
Optimal policy ==================================END
