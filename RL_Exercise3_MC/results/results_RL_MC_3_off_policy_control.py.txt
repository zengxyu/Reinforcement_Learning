Time step i:  2600000 ; Converging or not:  True ;delta:  0.08632668951884881
The average length of episodes: 2.7289788461538462
The average total reward of episode: 193.4714469230769
State values:
  45.457   53.948   62.484    0.000    0.000    0.000  975.478
  40.871   46.368   52.186   85.607    0.000  754.254    0.000
  39.487    0.000    0.000  174.198    0.000  452.561  361.563
  25.861   17.145    0.000  244.823  279.948    0.000  373.129
  14.504   11.555    0.000  247.109  277.587  316.878  325.248
State values ==================================END

State Counts:
85974.000 185064.000 183708.000 79237.000 37139.000 270637.000 94757.000
80241.000 114639.000 205418.000 137842.000 89706.000 274871.000 286431.000
65967.000 165018.000 184514.000 176907.000 117803.000 347632.000 187590.000
60685.000 15973.000 105946.000 43257.000 186288.000 176555.000 185673.000
43026.000 8642.000 46444.000 29518.000 42841.000 88927.000 90475.000
State Counts ==================================END

Output optimal policy with arrows:
   →        →        ↓        ●        ●        ●        ↖
   ↗        ↗        ↓        ↙        ●        ↗        ●
   ↑        ●        ●        ↓        ●        ↗        ↑
   ↖        ←        ●        ↘        →        ●        ↑
   ↑        ↖        ●        →        ↘        →        ↗
Optimal policy ==================================END

The number of correct policy: 15 /24