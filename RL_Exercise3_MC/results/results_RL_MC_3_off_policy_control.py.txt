Time step i:  4150000 ; Converging or not:  True ;delta:  0.09662588925359472
The average length of episodes: 2.998577831325301
The average total reward of episode: 222.17349228915663
The number of correct policy: 20 /24
State values:
  45.048   54.547   54.875    0.000    0.000    0.000  975.584
  43.682   50.919   71.440   42.624    0.000  756.453    0.000
  40.713    0.000    0.000  157.510    0.000  368.861  453.458
  34.639   29.635    0.000  239.369  251.111    0.000  396.969
  29.242   25.528    0.000  241.004  279.073  319.978  347.271
State values ==================================END

State Counts:
82175.000 305826.000 165265.000 127709.000 176160.000 584240.000 192448.000
114578.000 132713.000 333901.000 133367.000 163066.000 620258.000 424597.000
66856.000 165118.000 318740.000 194396.000 261495.000 259357.000 769675.000
46719.000 8072.000 107462.000 60102.000 110244.000 311912.000 768760.000
27186.000 8002.000 75331.000 74937.000 259123.000 352523.000 491785.000
State Counts ==================================END

Output optimal policy with arrows:
   ↗        ↘        ↓        ●        ●        ●        ↖
   ↗        ↗        ↘        ↓        ●        ↑        ●
   ↑        ●        ●        ↘        ●        ↑        ↖
   ↖        ←        ●        ↘        ↓        ●        ↗
   ↖        ↙        ●        ↘        ↘        →        ↗
Optimal policy ==================================END